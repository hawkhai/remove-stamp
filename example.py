#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°ç« æ“¦é™¤ç³»ç»Ÿ - ç»Ÿä¸€ç¤ºä¾‹ä»£ç 
åŸºäºGANçš„ç«¯åˆ°ç«¯å°ç« /æ°´å°/å™ªå£°å»é™¤ç³»ç»Ÿ

åŠŸèƒ½:
- å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼
- å•å¼ å›¾åƒå¤„ç†
- æ‰¹é‡å›¾åƒå¤„ç†
- ä¾èµ–æ£€æŸ¥

ä½¿ç”¨æ–¹æ³•:
1. å¿«é€Ÿæ¼”ç¤º: python example.py
2. å•å¼ å¤„ç†: python example.py --input_image image.jpg
3. æ‰¹é‡å¤„ç†: python example.py --input_dir images/ --output_dir results/
"""

import os
import argparse
import torch
import torch.nn as nn
import numpy as np
from PIL import Image
from torchvision import transforms
from torchvision.utils import save_image
from models.sa_gan import STRnet2
import cv2
from skimage import color


def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–æ˜¯å¦å®‰è£…"""
    print("ğŸ” æ£€æŸ¥ä¾èµ–...")
    deps_ok = True
    
    try:
        import torch
        print(f"   âœ… PyTorch: {torch.__version__}")
    except ImportError:
        print("   âŒ PyTorch æœªå®‰è£…")
        deps_ok = False
    
    try:
        import torchvision
        print(f"   âœ… TorchVision: {torchvision.__version__}")
    except ImportError:
        print("   âŒ TorchVision æœªå®‰è£…")
        deps_ok = False
    
    try:
        from PIL import Image
        print("   âœ… PIL/Pillow")
    except ImportError:
        print("   âŒ PIL/Pillow æœªå®‰è£…")
        deps_ok = False
    
    try:
        import numpy as np
        print(f"   âœ… NumPy: {np.__version__}")
    except ImportError:
        print("   âŒ NumPy æœªå®‰è£…")
        deps_ok = False
    
    try:
        import cv2
        print(f"   âœ… OpenCV: {cv2.__version__}")
    except ImportError:
        print("   âŒ OpenCV æœªå®‰è£…")
        deps_ok = False
    
    try:
        import skimage
        print(f"   âœ… scikit-image: {skimage.__version__}")
    except ImportError:
        print("   âŒ scikit-image æœªå®‰è£…")
        deps_ok = False
    
    if not deps_ok:
        print("\nâŒ è¯·å…ˆå®‰è£…å¿…è¦çš„ä¾èµ–:")
        print("pip install torch torchvision pillow numpy opencv-python scikit-image")
    
    return deps_ok


def load_image(image_path, load_size=(512, 512)):
    """åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ - ä¿®å¤ï¼šç§»é™¤é”™è¯¯çš„å½’ä¸€åŒ–"""
    transform = transforms.Compose([
        transforms.Resize(size=load_size, interpolation=Image.BICUBIC),
        transforms.ToTensor(),  # åªè½¬æ¢åˆ°[0,1]ï¼Œä¸åš[-1,1]å½’ä¸€åŒ–
    ])
    
    image = Image.open(image_path).convert('RGB')
    image_tensor = transform(image).unsqueeze(0)
    return image_tensor


def save_result(tensor, save_path):
    """ä¿å­˜å¤„ç†ç»“æœ - ä¿®å¤ï¼šç§»é™¤é”™è¯¯çš„åå½’ä¸€åŒ–"""
    # æ¨¡å‹è¾“å‡ºå·²ç»åœ¨[0,1]èŒƒå›´å†…ï¼Œä¸éœ€è¦åå½’ä¸€åŒ–
    tensor = torch.clamp(tensor, 0, 1)
    save_image(tensor, save_path)


def create_demo_image():
    """åˆ›å»ºæ¼”ç¤ºå›¾åƒ"""
    img = Image.new('RGB', (512, 512), 'white')
    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤æ‚çš„æ¼”ç¤ºå›¾åƒç”Ÿæˆé€»è¾‘
    return img


def process_model_mask(model_mask, target_size, enhance_quality=True, keep_grayscale=True):
    """
    å¤„ç†æ¨¡å‹ç”Ÿæˆçš„maskå¼ é‡ - æ”¯æŒç°åº¦å’ŒäºŒå€¼åŒ–
    
    Args:
        model_mask: torch.Tensor - æ¨¡å‹ç”Ÿæˆçš„mask
        target_size: tuple - ç›®æ ‡å°ºå¯¸ (width, height)
        enhance_quality: bool - æ˜¯å¦è¿›è¡Œè´¨é‡æ”¹è¿›åå¤„ç†
        keep_grayscale: bool - æ˜¯å¦ä¿ç•™ç°åº¦ä¿¡æ¯ï¼ˆé¿å…é”¯é½¿ï¼‰
    
    Returns:
        numpy.ndarray - å¤„ç†åçš„mask (0-255)
    """
    # å¤„ç†å¼ é‡ç»´åº¦
    if model_mask.dim() == 4:
        model_mask = model_mask.squeeze(0)
    if model_mask.dim() == 3:
        model_mask = model_mask.mean(dim=0)  # å¤šé€šé“å–å¹³å‡
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    mask_np = model_mask.detach().cpu().numpy()
    
    # è°ƒæ•´å°ºå¯¸
    if mask_np.shape != target_size[::-1]:  # target_sizeæ˜¯(w,h)ï¼Œéœ€è¦è½¬æ¢ä¸º(h,w)
        mask_np = cv2.resize(mask_np, target_size, interpolation=cv2.INTER_LINEAR)
    
    # å½’ä¸€åŒ–åˆ°[0,255]
    mask_min, mask_max = mask_np.min(), mask_np.max()
    if mask_max > mask_min:
        mask_np = (mask_np - mask_min) / (mask_max - mask_min) * 255
    else:
        mask_np = np.zeros_like(mask_np) * 255
    
    mask_np = mask_np.astype(np.uint8)
    
    if keep_grayscale:
        # ä¿ç•™ç°åº¦ä¿¡æ¯ï¼Œé¿å…é”¯é½¿
        # æ£€æŸ¥åŸå§‹maskçš„å¹³å‡å€¼æ¥åˆ¤æ–­éœ€è¦å¦‚ä½•å¤„ç†æ–¹å‘
        mask_mean = np.mean(mask_np)
        
        # é‡æ–°åˆ¤æ–­maskæ–¹å‘ï¼šé€šå¸¸æ¨¡å‹è¾“å‡ºä¸­ï¼Œå°ç« åŒºåŸŸåº”è¯¥æ˜¯é«˜å€¼
        # å¦‚æœåŸå§‹maskå¹³å‡å€¼è¾ƒå¤§ï¼Œè¯´æ˜å¤§éƒ¨åˆ†æ˜¯é«˜å€¼ï¼ˆå¯èƒ½æ˜¯èƒŒæ™¯ï¼‰
        if mask_mean > 127.5:  # åŸå§‹maskåäº®ï¼Œå¯èƒ½éœ€è¦åè½¬
            processed_mask = 255 - mask_np  # åè½¬ï¼Œè®©å°ç« åŒºåŸŸå˜ä¸ºä½å€¼
        else:
            processed_mask = mask_np
        
        # ç°åº¦æ¨¡å¼çš„è´¨é‡æ”¹è¿›
        if enhance_quality:
            # 1. é«˜æ–¯æ¨¡ç³Šå¹³æ»‘è¾¹ç¼˜ï¼Œé¿å…é”¯é½¿
            processed_mask = cv2.GaussianBlur(processed_mask, (3, 3), 0.5)
            
            # 2. è½»å¾®çš„å¯¹æ¯”åº¦å¢å¼º
            processed_mask = cv2.convertScaleAbs(processed_mask, alpha=1.1, beta=0)
            
            # 3. ç¡®ä¿åœ¨[0,255]èŒƒå›´å†…
            processed_mask = np.clip(processed_mask, 0, 255)
    
    else:
        # ä¼ ç»ŸäºŒå€¼åŒ–æ¨¡å¼
        _, binary_mask = cv2.threshold(mask_np, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # æ£€æŸ¥åŸå§‹maskçš„å¹³å‡å€¼æ¥åˆ¤æ–­éœ€è¦å¦‚ä½•å¤„ç†
        mask_mean = np.mean(mask_np)
        
        # å¦‚æœåŸå§‹maskå¹³å‡å€¼è¾ƒå°ï¼Œè¯´æ˜å°ç« åŒºåŸŸæ˜¯ä½å€¼
        if mask_mean < 127.5:  # åŸå§‹maskåæš—ï¼Œå°ç« åŒºåŸŸæ˜¯ä½å€¼
            binary_mask = 255 - binary_mask  # åè½¬ï¼Œè®©å°ç« åŒºåŸŸå˜ä¸ºç™½è‰²
        
        # äºŒå€¼åŒ–æ¨¡å¼çš„è´¨é‡æ”¹è¿›
        if enhance_quality:
            # 1. å»é™¤å°å™ªå£°ç‚¹
            kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel_small)
            
            # 2. å¡«å……å°ç©ºæ´
            binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel_small)
            
            # 3. å¹³æ»‘è¾¹ç¼˜
            binary_mask = cv2.medianBlur(binary_mask, 3)
            
            # 4. è½»å¾®è†¨èƒ€ï¼Œç¡®ä¿å°ç« åŒºåŸŸå®Œæ•´
            kernel_dilate = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
            binary_mask = cv2.dilate(binary_mask, kernel_dilate, iterations=1)
        
        processed_mask = binary_mask
    
    return processed_mask.astype(np.uint8)


def extract_stamp_and_mask(original_image, cleaned_image, model_mask, enhance_mask=True, use_grayscale=True):
    """
    åŸºäºæ¨¡å‹maskçš„å°ç« æå–ç®—æ³• - æ”¯æŒç°åº¦å’ŒäºŒå€¼åŒ–
    
    Args:
        original_image: PIL Image - åŸå§‹å¸¦å°ç« å›¾åƒ
        cleaned_image: PIL Image - æ“¦é™¤å°ç« åçš„å›¾åƒ
        model_mask: torch.Tensor - æ¨¡å‹ç”Ÿæˆçš„å°ç« åŒºåŸŸmask
        enhance_mask: bool - æ˜¯å¦è¿›è¡Œmaskè´¨é‡æ”¹è¿›
        use_grayscale: bool - æ˜¯å¦ä½¿ç”¨ç°åº¦maskï¼ˆé¿å…é”¯é½¿ï¼‰
    
    Returns:
        stamp_image: PIL Image - æå–çš„å°ç« å›¾åƒ
        mask_image: PIL Image - å°ç« åŒºåŸŸmask
        stats: dict - æå–ç»Ÿè®¡ä¿¡æ¯
    """
    # ç¡®ä¿å›¾åƒå°ºå¯¸ä¸€è‡´
    if original_image.size != cleaned_image.size:
        cleaned_image = cleaned_image.resize(original_image.size, Image.BICUBIC)
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    orig_np = np.array(original_image)
    clean_np = np.array(cleaned_image)
    
    # å¤„ç†æ¨¡å‹mask
    processed_mask = process_model_mask(model_mask, original_image.size, 
                                       enhance_quality=enhance_mask, 
                                       keep_grayscale=use_grayscale)
    
    # æå–å°ç« 
    stamp_np = orig_np.copy()
    
    if use_grayscale:
        # ç°åº¦æ¨¡å¼ï¼šä½¿ç”¨è½¯æ··åˆï¼Œé¿å…é”¯é½¿
        mask_weight = processed_mask.astype(np.float32) / 255.0
        
        # ç°åœ¨processed_maskä¸­ï¼šä½å€¼=å°ç« åŒºåŸŸï¼Œé«˜å€¼=èƒŒæ™¯åŒºåŸŸ
        # ä½¿ç”¨é˜ˆå€¼æ¥å†³å®šå“ªäº›åŒºåŸŸè®¾ä¸ºç™½è‰²èƒŒæ™¯
        background_threshold = 0.5  # ä½¿ç”¨ä¸­å€¼ä½œä¸ºé˜ˆå€¼
        background_mask = mask_weight > background_threshold  # é«˜å€¼åŒºåŸŸä¸ºèƒŒæ™¯
        
        # å°†èƒŒæ™¯åŒºåŸŸè®¾ä¸ºç™½è‰²ï¼Œä¿ç•™å°ç« åŒºåŸŸ
        stamp_np[background_mask] = [255, 255, 255]
    else:
        # äºŒå€¼åŒ–æ¨¡å¼ï¼šç¡¬è¾¹ç¼˜
        # éœ€è¦é‡æ–°æ£€æŸ¥äºŒå€¼åŒ–åçš„maskæ–¹å‘
        stamp_np[processed_mask > 127] = [255, 255, 255]  # å°†é«˜å€¼åŒºåŸŸè®¾ä¸ºç™½è‰²èƒŒæ™¯
    
    # è½¬æ¢ä¸ºPILå›¾åƒ
    stamp_image = Image.fromarray(stamp_np)
    mask_image = Image.fromarray(processed_mask, mode='L')
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    total_pixels = processed_mask.shape[0] * processed_mask.shape[1]
    
    if use_grayscale:
        # ç°åº¦æ¨¡å¼ï¼šç»Ÿè®¡ä½å€¼åŒºåŸŸä½œä¸ºå°ç« 
        stamp_pixels = np.sum(processed_mask <= 127)  # ä½äºç­‰äºä¸­å€¼çš„åƒç´ ä¸ºå°ç« 
    else:
        # äºŒå€¼åŒ–æ¨¡å¼ï¼šç»Ÿè®¡ä½å€¼åŒºåŸŸä½œä¸ºå°ç« 
        stamp_pixels = np.sum(processed_mask <= 127)
    
    stamp_ratio = stamp_pixels / total_pixels if total_pixels > 0 else 0
    
    # è®¡ç®—åŸå›¾å’Œæ¸…ç†å›¾çš„LABå·®å¼‚ï¼ˆç”¨äºè´¨é‡è¯„ä¼°ï¼‰
    try:
        orig_lab = color.rgb2lab(orig_np / 255.0)
        clean_lab = color.rgb2lab(clean_np / 255.0)
        lab_diff = np.sqrt(np.sum((orig_lab - clean_lab) ** 2, axis=2))
        max_lab_diff = np.max(lab_diff)
        mean_lab_diff = np.mean(lab_diff)
        
        # è®¡ç®—å°ç« åŒºåŸŸçš„å¹³å‡LABå·®å¼‚
        stamp_lab_diff = np.mean(lab_diff[processed_mask <= 127]) if stamp_pixels > 0 else 0
    except Exception:
        max_lab_diff = mean_lab_diff = stamp_lab_diff = 0
    
    stats = {
        'total_pixels': total_pixels,
        'stamp_pixels': stamp_pixels,
        'stamp_ratio': stamp_ratio,
        'max_lab_diff': max_lab_diff,
        'mean_lab_diff': mean_lab_diff,
        'stamp_lab_diff': stamp_lab_diff,
        'method': 'model_mask_grayscale' if use_grayscale else 'model_mask_binary'
    }
    
    return stamp_image, mask_image, stats


def ensure_dir(file_path):
    """ç¡®ä¿æ–‡ä»¶è·¯å¾„çš„ç›®å½•å­˜åœ¨"""
    directory = os.path.dirname(file_path)
    if directory and not os.path.exists(directory):
        os.makedirs(directory, exist_ok=True)


def tensor_to_pil(tensor):
    """å°†tensorè½¬æ¢ä¸ºPILå›¾åƒ"""
    if tensor.dim() == 4:
        tensor = tensor.squeeze(0)
    
    # ç¡®ä¿åœ¨[0,1]èŒƒå›´å†…
    tensor = torch.clamp(tensor, 0, 1)
    
    # è½¬æ¢ä¸ºnumpyå¹¶è°ƒæ•´ç»´åº¦é¡ºåº
    np_array = tensor.permute(1, 2, 0).numpy()
    np_array = (np_array * 255).astype(np.uint8)
    
    return Image.fromarray(np_array)


def process_image(model_path, input_image_path, output_path, verbose=True, save_debug=False, extract_stamp=True, enhance_mask=True, use_grayscale_mask=True):
    """
    å¤„ç†å•å¼ å›¾åƒ - å°ç« æ“¦é™¤ + åŸºäºç°åº¦/äºŒå€¼åŒ–çš„å°ç« æå–
    
    Args:
        save_debug: å¦‚æœä¸ºTrueï¼Œä¿å­˜è°ƒè¯•è¾“å‡ºï¼ˆå¤šå°ºåº¦è¾“å‡ºå’ŒåŸå§‹æ¨¡å‹maskï¼‰
        extract_stamp: å¦‚æœä¸ºTrueï¼Œæå–å°ç« å’Œç”Ÿæˆmask
        enhance_mask: å¦‚æœä¸ºTrueï¼Œè¿›è¡Œmaskè´¨é‡æ”¹è¿›
        use_grayscale_mask: å¦‚æœä¸ºTrueï¼Œä½¿ç”¨ç°åº¦maskï¼ˆé¿å…é”¯é½¿ï¼‰
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    if verbose:
        print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    if verbose:
        print("ğŸ”§ åŠ è½½æ¨¡å‹...")
    model = STRnet2(3)
    
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location=device))
        if verbose:
            print(f"âœ… åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {os.path.basename(model_path)}")
    else:
        if verbose:
            print("âš ï¸  ä½¿ç”¨éšæœºåˆå§‹åŒ–æ¨¡å‹ï¼ˆæ¼”ç¤ºæ¨¡å¼ï¼‰")
    
    model.to(device)
    model.eval()
    
    # å¤„ç†å›¾åƒ
    if verbose:
        print(f"ğŸ–¼ï¸  å¤„ç†å›¾åƒ: {os.path.basename(input_image_path)}")
    
    input_tensor = load_image(input_image_path).to(device)
    
    # åŠ è½½åŸå§‹å›¾åƒç”¨äºå¯¹æ¯”
    original_pil = Image.open(input_image_path).convert('RGB')
    
    with torch.no_grad():
        # è·å–æ¨¡å‹çš„æ‰€æœ‰è¾“å‡º
        out1, out2, out3, g_images, mm = model(input_tensor)
        
        # è½¬æ¢åˆ°CPU
        g_image = g_images.data.cpu()
        
        # å…³é”®ä¿®å¤ï¼šåœ¨æ¨ç†æ—¶ï¼Œæˆ‘ä»¬åº”è¯¥ç›´æ¥ä½¿ç”¨ç”Ÿæˆçš„å›¾åƒ
        # åŸå§‹test.pyä¸­çš„maskæ··åˆæ˜¯ç”¨äºè®­ç»ƒ/æµ‹è¯•æ—¶æœ‰ground truthçš„æƒ…å†µ
        # åœ¨å®é™…æ¨ç†æ—¶ï¼Œæ¨¡å‹çš„æœ€ç»ˆè¾“å‡ºg_imageså°±æ˜¯æˆ‘ä»¬è¦çš„ç»“æœ
        result = g_image
        
        # è½¬æ¢ä¸ºPILå›¾åƒç”¨äºå°ç« æå–
        cleaned_pil = tensor_to_pil(result)
        
        # è°ƒè¯•æ¨¡å¼ï¼šä¿å­˜å¤šå°ºåº¦è¾“å‡º
        if save_debug:
            out1_cpu = out1.data.cpu()
            out2_cpu = out2.data.cpu() 
            out3_cpu = out3.data.cpu()
            
            out1_path = output_path.replace('.jpg', '_debug_out1.jpg')
            out2_path = output_path.replace('.jpg', '_debug_out2.jpg')
            out3_path = output_path.replace('.jpg', '_debug_out3.jpg')
            
            ensure_dir(out1_path)
            save_result(out1_cpu, out1_path)
            save_result(out2_cpu, out2_path)
            save_result(out3_cpu, out3_path)
            
            if verbose:
                print(f"ğŸ”§ è°ƒè¯•è¾“å‡ºå·²ä¿å­˜")
        
        # æå–å°ç« å’Œç”Ÿæˆmask
        if extract_stamp:
            if verbose:
                mode_str = "ç°åº¦mask" if use_grayscale_mask else "äºŒå€¼åŒ–mask"
                print(f"ğŸ” æå–å°ç«  ({mode_str})")
            
            # ä½¿ç”¨å°ç« æå–ç®—æ³•
            stamp_image, mask_image, diff_stats = extract_stamp_and_mask(
                original_pil, cleaned_pil, mm, 
                enhance_mask=enhance_mask,
                use_grayscale=use_grayscale_mask
            )
            
            # ä¿å­˜å¿…è¦è¾“å‡ºï¼šå°ç« å’Œmask
            stamp_path = output_path.replace('.jpg', '_stamp.jpg')
            mask_path = output_path.replace('.jpg', '_mask.png')
            
            ensure_dir(stamp_path)
            ensure_dir(mask_path)
            
            stamp_image.save(stamp_path)
            mask_image.save(mask_path)
            
            # è°ƒè¯•æ¨¡å¼ï¼šä¿å­˜åŸå§‹æ¨¡å‹mask
            if save_debug:
                model_mask_path = output_path.replace('.jpg', '_debug_model_mask.png')
                ensure_dir(model_mask_path)
                model_mask_vis = tensor_to_pil(mm)
                model_mask_vis.save(model_mask_path)
            
            if verbose:
                print(f"ğŸ“„ å°ç« ä¿å­˜åˆ°: {os.path.basename(stamp_path)}")
                print(f"ğŸ­ Maskä¿å­˜åˆ°: {os.path.basename(mask_path)}")
                print(f"ğŸ“Š å°ç« åŒºåŸŸå æ¯”: {diff_stats['stamp_ratio']:.2%}")
                print(f"ğŸ“Š å°ç« åŒºåŸŸLABå·®å¼‚: {diff_stats['stamp_lab_diff']:.2f}")
                print(f"ğŸ“Š æ•´ä½“LABå·®å¼‚: {diff_stats['mean_lab_diff']:.2f}")
                if save_debug:
                    print(f"ğŸ”§ è°ƒè¯•maskä¿å­˜åˆ°: {os.path.basename(model_mask_path)}")
    
    # ä¿å­˜æœ€ç»ˆç»“æœ
    ensure_dir(output_path)
    save_result(result, output_path)
    
    if verbose:
        print(f"âœ… å®Œæˆ! ä¿å­˜åˆ°: {output_path}")
        if save_debug:
            print("ğŸ”§ è°ƒè¯•æ¨¡å¼: å·²ä¿å­˜é¢å¤–çš„è°ƒè¯•æ–‡ä»¶")
    
    return output_path


def batch_process(model_path, input_dir, output_dir, extract_stamp=True):
    """æ‰¹é‡å¤„ç†å›¾åƒï¼ŒåŒ…å«åŸºäºæ¨¡å‹maskçš„å°ç« æå–"""
    supported_formats = ('.png', '.jpg', '.jpeg', '.bmp', '.PNG', '.JPG', '.JPEG', '.BMP')
    
    # è·å–å›¾åƒæ–‡ä»¶
    image_files = []
    for root, dirs, files in os.walk(input_dir):
        for file in files:
            if file.endswith(supported_formats):
                image_files.append(os.path.join(root, file))
    
    if not image_files:
        print(f"âŒ åœ¨ç›®å½• {input_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
    os.makedirs(output_dir, exist_ok=True)
    
    # æ‰¹é‡å¤„ç†
    success_count = 0
    for i, image_path in enumerate(image_files):
        print(f"ğŸ“Š è¿›åº¦: {i+1}/{len(image_files)} - {os.path.basename(image_path)}")
        try:
            output_filename = f"cleaned_{os.path.basename(image_path).replace('.png', '.jpg')}"
            output_path = os.path.join(output_dir, output_filename)
            process_image(
                model_path=model_path, 
                input_image_path=image_path, 
                output_path=output_path, 
                verbose=False,
                extract_stamp=extract_stamp
            )
            success_count += 1
        except Exception as e:
            print(f"âŒ å¤„ç† {os.path.basename(image_path)} å‡ºé”™: {str(e)}")
    
    print(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ! æˆåŠŸå¤„ç† {success_count}/{len(image_files)} ä¸ªæ–‡ä»¶")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
    if extract_stamp:
        print("ğŸ“„ æ¯ä¸ªæ–‡ä»¶ç”Ÿæˆ: æ¸…ç†å›¾åƒ + å°ç« å›¾åƒ + Maskå›¾åƒ")


def quick_demo():
    """å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼ - OTSUäºŒå€¼åŒ–ç‰ˆæœ¬"""
    print("ğŸš€ å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼ (OTSUäºŒå€¼åŒ–)")
    print("-" * 50)
    
    # åˆ›å»ºæ¼”ç¤ºå›¾åƒ
    demo_image = create_demo_image()
    demo_path = "demo_input.jpg"
    demo_image.save(demo_path)
    print(f"ğŸ“ åˆ›å»ºæ¼”ç¤ºå›¾åƒ: {demo_path}")
    
    # å¤„ç†å›¾åƒ - æ ‡å‡†æ¨¡å¼
    output_path = "demo_output_final.jpg"
    process_image("./models/pre_model.pth", demo_path, output_path, save_debug=False)
    
    print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆ!")
    print(f"   è¾“å…¥å›¾åƒ: {demo_path}")
    print(f"   æ¸…ç†å›¾åƒ: {output_path}")
    print(f"   å°ç« å›¾åƒ: demo_output_final_stamp.jpg")
    print(f"   Maskå›¾åƒ: demo_output_final_mask.png")
    print("\nğŸ”§ ç®—æ³•è¯´æ˜:")
    print("   - ä¿®å¤äº†å›¾åƒé¢„å¤„ç†ï¼ˆç§»é™¤é”™è¯¯å½’ä¸€åŒ–ï¼‰")
    print("   - ä¿®å¤äº†æ¨ç†é€»è¾‘ï¼ˆç›´æ¥ä½¿ç”¨æ¨¡å‹ç”Ÿæˆå›¾åƒï¼‰")
    print("   - ä½¿ç”¨OTSUç®—æ³•è‡ªåŠ¨äºŒå€¼åŒ–æ¨¡å‹mask")
    print("   - ç®€å•é«˜æ•ˆï¼Œé¿å…è¿‡åº¦åå¤„ç†å¤±çœŸ")
    
    return demo_path, output_path


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å°ç« æ“¦é™¤ç³»ç»Ÿ (OTSUäºŒå€¼åŒ–å°ç« æå–)')
    parser.add_argument('--model_path', type=str, default='./models/pre_model.pth',
                        help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--input_image', type=str, default=r'image\2.png', help='è¾“å…¥å›¾åƒè·¯å¾„')
    parser.add_argument('--input_dir', type=str, help='è¾“å…¥å›¾åƒç›®å½•ï¼ˆæ‰¹é‡å¤„ç†ï¼‰')
    parser.add_argument('--output_path', type=str, default='./results/cleaned_image.jpg',
                        help='è¾“å‡ºå›¾åƒè·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./results/',
                        help='è¾“å‡ºç›®å½•ï¼ˆæ‰¹é‡å¤„ç†ï¼‰')
    parser.add_argument('--debug', action='store_true',
                        help='è°ƒè¯•æ¨¡å¼ï¼šä¿å­˜é¢å¤–çš„è°ƒè¯•æ–‡ä»¶')
    parser.add_argument('--no_extract', action='store_true',
                        help='ä¸æå–å°ç« å’Œmask')
    parser.add_argument('--no_enhance_mask', action='store_true',
                        help='ä¸è¿›è¡Œmaskè´¨é‡æ”¹è¿›åå¤„ç†')
    parser.add_argument('--binary_mask', action='store_true',
                        help='ä½¿ç”¨äºŒå€¼åŒ–maskï¼ˆé»˜è®¤ä½¿ç”¨ç°åº¦maské¿å…é”¯é½¿ï¼‰')
    
    args = parser.parse_args()
    
    print("=" * 50)
    print("ğŸ¯ å°ç« æ“¦é™¤ç³»ç»Ÿ")
    print("=" * 50)
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        return
    
    print()
    
    try:
        if args.input_image:
            # å•å¼ å›¾åƒå¤„ç†
            if not os.path.exists(args.input_image):
                print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {args.input_image}")
                return
            mode_desc = "äºŒå€¼åŒ–" if args.binary_mask else "ç°åº¦"
            print(f"ğŸ“· å•å¼ å›¾åƒå¤„ç†æ¨¡å¼ ({mode_desc}maskå°ç« æå–)")
            process_image(
                model_path=args.model_path, 
                input_image_path=args.input_image, 
                output_path=args.output_path, 
                save_debug=args.debug,
                extract_stamp=not args.no_extract,
                enhance_mask=not args.no_enhance_mask,
                use_grayscale_mask=not args.binary_mask
            )
            
        elif args.input_dir:
            # æ‰¹é‡å¤„ç†
            if not os.path.exists(args.input_dir):
                print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {args.input_dir}")
                return
            print("ğŸ“ æ‰¹é‡å¤„ç†æ¨¡å¼ (OTSUäºŒå€¼åŒ–å°ç« æå–)")
            batch_process(args.model_path, args.input_dir, args.output_dir, 
                         extract_stamp=not args.no_extract)
            
        else:
            # é»˜è®¤æ¼”ç¤ºæ¨¡å¼
            quick_demo()
            print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
            print("  å•å¼ å¤„ç†: python example.py --input_image image.jpg")
            print("  æ‰¹é‡å¤„ç†: python example.py --input_dir images/ --output_dir results/")
            print("  ä¸æå–å°ç« : python example.py --input_image image.jpg --no_extract")
            print("  è°ƒè¯•æ¨¡å¼: python example.py --input_image image.jpg --debug")
            print("  äºŒå€¼åŒ–mask: python example.py --input_image image.jpg --binary_mask")
            
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {str(e)}")
        print("è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å’Œä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…")


if __name__ == "__main__":
    main()

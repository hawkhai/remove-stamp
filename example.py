#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°ç« æ“¦é™¤ç³»ç»Ÿ - ç»Ÿä¸€ç¤ºä¾‹ä»£ç 
åŸºäºGANçš„ç«¯åˆ°ç«¯å°ç« /æ°´å°/å™ªå£°å»é™¤ç³»ç»Ÿ

åŠŸèƒ½:
- å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼
- å•å¼ å›¾åƒå¤„ç†
- æ‰¹é‡å›¾åƒå¤„ç†
- ä¾èµ–æ£€æŸ¥

ä½¿ç”¨æ–¹æ³•:
1. å¿«é€Ÿæ¼”ç¤º: python example.py
2. å•å¼ å¤„ç†: python example.py --input_image image.jpg
3. æ‰¹é‡å¤„ç†: python example.py --input_dir images/ --output_dir results/
"""

import os
import argparse
import torch
import torch.nn as nn
import numpy as np
from PIL import Image
from torchvision import transforms
from torchvision.utils import save_image
from models.sa_gan import STRnet2


def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–æ˜¯å¦å®‰è£…"""
    print("ğŸ” æ£€æŸ¥ä¾èµ–...")
    deps_ok = True
    
    try:
        import torch
        print(f"   âœ… PyTorch: {torch.__version__}")
    except ImportError:
        print("   âŒ PyTorch æœªå®‰è£…")
        deps_ok = False
    
    try:
        import torchvision
        print(f"   âœ… TorchVision: {torchvision.__version__}")
    except ImportError:
        print("   âŒ TorchVision æœªå®‰è£…")
        deps_ok = False
    
    try:
        from PIL import Image
        print("   âœ… PIL/Pillow")
    except ImportError:
        print("   âŒ PIL/Pillow æœªå®‰è£…")
        deps_ok = False
    
    try:
        import numpy as np
        print(f"   âœ… NumPy: {np.__version__}")
    except ImportError:
        print("   âŒ NumPy æœªå®‰è£…")
        deps_ok = False
    
    if not deps_ok:
        print("\nâŒ è¯·å…ˆå®‰è£…å¿…è¦çš„ä¾èµ–:")
        print("pip install torch torchvision pillow numpy")
    
    return deps_ok


def load_image(image_path, load_size=(512, 512)):
    """åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ"""
    transform = transforms.Compose([
        transforms.Resize(size=load_size, interpolation=Image.BICUBIC),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])
    
    image = Image.open(image_path).convert('RGB')
    image_tensor = transform(image).unsqueeze(0)
    return image_tensor


def save_result(tensor, save_path):
    """ä¿å­˜å¤„ç†ç»“æœ"""
    tensor = (tensor + 1) / 2.0  # åå½’ä¸€åŒ–åˆ°[0, 1]
    tensor = torch.clamp(tensor, 0, 1)
    save_image(tensor, save_path)


def create_demo_image():
    """åˆ›å»ºæ¼”ç¤ºå›¾åƒ"""
    img = Image.new('RGB', (512, 512), 'white')
    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤æ‚çš„æ¼”ç¤ºå›¾åƒç”Ÿæˆé€»è¾‘
    return img


def process_image(model_path, input_image_path, output_path, verbose=True):
    """å¤„ç†å•å¼ å›¾åƒ"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    if verbose:
        print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    if verbose:
        print("ğŸ”§ åŠ è½½æ¨¡å‹...")
    model = STRnet2(3)
    
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location=device))
        if verbose:
            print(f"âœ… åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {os.path.basename(model_path)}")
    else:
        if verbose:
            print("âš ï¸  ä½¿ç”¨éšæœºåˆå§‹åŒ–æ¨¡å‹ï¼ˆæ¼”ç¤ºæ¨¡å¼ï¼‰")
    
    model.to(device)
    model.eval()
    
    # å¤„ç†å›¾åƒ
    if verbose:
        print(f"ğŸ–¼ï¸  å¤„ç†å›¾åƒ: {os.path.basename(input_image_path)}")
    
    input_tensor = load_image(input_image_path).to(device)
    
    with torch.no_grad():
        _, _, _, final_output, _ = model(input_tensor)
        result = final_output.cpu()
    
    # ä¿å­˜ç»“æœ
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    save_result(result, output_path)
    
    if verbose:
        print(f"âœ… å®Œæˆ! ä¿å­˜åˆ°: {output_path}")
    
    return output_path


def batch_process(model_path, input_dir, output_dir):
    """æ‰¹é‡å¤„ç†å›¾åƒ"""
    supported_formats = ('.png', '.jpg', '.jpeg', '.bmp', '.PNG', '.JPG', '.JPEG', '.BMP')
    
    # è·å–å›¾åƒæ–‡ä»¶
    image_files = []
    for root, dirs, files in os.walk(input_dir):
        for file in files:
            if file.endswith(supported_formats):
                image_files.append(os.path.join(root, file))
    
    if not image_files:
        print(f"âŒ åœ¨ç›®å½• {input_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
    os.makedirs(output_dir, exist_ok=True)
    
    # æ‰¹é‡å¤„ç†
    for i, image_path in enumerate(image_files):
        print(f"ğŸ“Š è¿›åº¦: {i+1}/{len(image_files)}")
        try:
            output_filename = f"cleaned_{os.path.basename(image_path)}"
            output_path = os.path.join(output_dir, output_filename)
            process_image(model_path, image_path, output_path, verbose=False)
        except Exception as e:
            print(f"âŒ å¤„ç† {os.path.basename(image_path)} å‡ºé”™: {str(e)}")
    
    print(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ! ç»“æœä¿å­˜åœ¨: {output_dir}")


def quick_demo():
    """å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼"""
    print("ğŸš€ å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼")
    print("-" * 40)
    
    # åˆ›å»ºæ¼”ç¤ºå›¾åƒ
    demo_image = create_demo_image()
    demo_path = "demo_input.jpg"
    demo_image.save(demo_path)
    print(f"ğŸ“ åˆ›å»ºæ¼”ç¤ºå›¾åƒ: {demo_path}")
    
    # å¤„ç†å›¾åƒ
    output_path = "demo_output.jpg"
    process_image("./models/pre_model.pth", demo_path, output_path)
    
    print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆ!")
    print(f"   è¾“å…¥: {demo_path}")
    print(f"   è¾“å‡º: {output_path}")
    
    return demo_path, output_path


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å°ç« æ“¦é™¤ç³»ç»Ÿ')
    parser.add_argument('--model_path', type=str, default='./models/pre_model.pth',
                        help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--input_image', type=str, default=r'image\2.png', help='è¾“å…¥å›¾åƒè·¯å¾„')
    parser.add_argument('--input_dir', type=str, help='è¾“å…¥å›¾åƒç›®å½•ï¼ˆæ‰¹é‡å¤„ç†ï¼‰')
    parser.add_argument('--output_path', type=str, default='./results/cleaned_image.jpg',
                        help='è¾“å‡ºå›¾åƒè·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./results/',
                        help='è¾“å‡ºç›®å½•ï¼ˆæ‰¹é‡å¤„ç†ï¼‰')
    
    args = parser.parse_args()
    
    print("=" * 50)
    print("ğŸ¯ å°ç« æ“¦é™¤ç³»ç»Ÿ")
    print("=" * 50)
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        return
    
    print()
    
    try:
        if args.input_image:
            # å•å¼ å›¾åƒå¤„ç†
            if not os.path.exists(args.input_image):
                print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {args.input_image}")
                return
            print("ğŸ“· å•å¼ å›¾åƒå¤„ç†æ¨¡å¼")
            process_image(args.model_path, args.input_image, args.output_path)
            
        elif args.input_dir:
            # æ‰¹é‡å¤„ç†
            if not os.path.exists(args.input_dir):
                print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {args.input_dir}")
                return
            print("ğŸ“ æ‰¹é‡å¤„ç†æ¨¡å¼")
            batch_process(args.model_path, args.input_dir, args.output_dir)
            
        else:
            # é»˜è®¤æ¼”ç¤ºæ¨¡å¼
            quick_demo()
            print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
            print("  å•å¼ å¤„ç†: python example.py --input_image image.jpg")
            print("  æ‰¹é‡å¤„ç†: python example.py --input_dir images/ --output_dir results/")
            
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {str(e)}")
        print("è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å’Œä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…")


if __name__ == "__main__":
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°ç« æ“¦é™¤ç³»ç»Ÿ - ç»Ÿä¸€ç¤ºä¾‹ä»£ç 
åŸºäºGANçš„ç«¯åˆ°ç«¯å°ç« /æ°´å°/å™ªå£°å»é™¤ç³»ç»Ÿ

åŠŸèƒ½:
- å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼
- å•å¼ å›¾åƒå¤„ç†
- æ‰¹é‡å›¾åƒå¤„ç†
- ä¾èµ–æ£€æŸ¥

ä½¿ç”¨æ–¹æ³•:
1. å¿«é€Ÿæ¼”ç¤º: python example.py
2. å•å¼ å¤„ç†: python example.py --input_image image.jpg
3. æ‰¹é‡å¤„ç†: python example.py --input_dir images/ --output_dir results/
"""

import os
import argparse
import torch
import torch.nn as nn
import numpy as np
from PIL import Image
from torchvision import transforms
from torchvision.utils import save_image
from models.sa_gan import STRnet2
import cv2
from skimage import color


def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–æ˜¯å¦å®‰è£…"""
    print("ğŸ” æ£€æŸ¥ä¾èµ–...")
    deps_ok = True
    
    try:
        import torch
        print(f"   âœ… PyTorch: {torch.__version__}")
    except ImportError:
        print("   âŒ PyTorch æœªå®‰è£…")
        deps_ok = False
    
    try:
        import torchvision
        print(f"   âœ… TorchVision: {torchvision.__version__}")
    except ImportError:
        print("   âŒ TorchVision æœªå®‰è£…")
        deps_ok = False
    
    try:
        from PIL import Image
        print("   âœ… PIL/Pillow")
    except ImportError:
        print("   âŒ PIL/Pillow æœªå®‰è£…")
        deps_ok = False
    
    try:
        import numpy as np
        print(f"   âœ… NumPy: {np.__version__}")
    except ImportError:
        print("   âŒ NumPy æœªå®‰è£…")
        deps_ok = False
    
    try:
        import cv2
        print(f"   âœ… OpenCV: {cv2.__version__}")
    except ImportError:
        print("   âŒ OpenCV æœªå®‰è£…")
        deps_ok = False
    
    try:
        import skimage
        print(f"   âœ… scikit-image: {skimage.__version__}")
    except ImportError:
        print("   âŒ scikit-image æœªå®‰è£…")
        deps_ok = False
    
    if not deps_ok:
        print("\nâŒ è¯·å…ˆå®‰è£…å¿…è¦çš„ä¾èµ–:")
        print("pip install torch torchvision pillow numpy opencv-python scikit-image")
    
    return deps_ok


def load_image(image_path, load_size=(512, 512)):
    """åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ - ä¿®å¤ï¼šç§»é™¤é”™è¯¯çš„å½’ä¸€åŒ–"""
    transform = transforms.Compose([
        transforms.Resize(size=load_size, interpolation=Image.BICUBIC),
        transforms.ToTensor(),  # åªè½¬æ¢åˆ°[0,1]ï¼Œä¸åš[-1,1]å½’ä¸€åŒ–
    ])
    
    image = Image.open(image_path).convert('RGB')
    image_tensor = transform(image).unsqueeze(0)
    return image_tensor


def save_result(tensor, save_path):
    """ä¿å­˜å¤„ç†ç»“æœ - ä¿®å¤ï¼šç§»é™¤é”™è¯¯çš„åå½’ä¸€åŒ–"""
    # æ¨¡å‹è¾“å‡ºå·²ç»åœ¨[0,1]èŒƒå›´å†…ï¼Œä¸éœ€è¦åå½’ä¸€åŒ–
    tensor = torch.clamp(tensor, 0, 1)
    save_image(tensor, save_path)


def create_demo_image():
    """åˆ›å»ºæ¼”ç¤ºå›¾åƒ"""
    img = Image.new('RGB', (512, 512), 'white')
    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤æ‚çš„æ¼”ç¤ºå›¾åƒç”Ÿæˆé€»è¾‘
    return img


def process_model_mask(model_mask, target_size, enhance_quality=True, keep_grayscale=True):
    """
    å¤„ç†æ¨¡å‹ç”Ÿæˆçš„maskå¼ é‡ - æ”¯æŒç°åº¦å’ŒäºŒå€¼åŒ–
    
    Args:
        model_mask: torch.Tensor - æ¨¡å‹ç”Ÿæˆçš„mask
        target_size: tuple - ç›®æ ‡å°ºå¯¸ (width, height)
        enhance_quality: bool - æ˜¯å¦è¿›è¡Œè´¨é‡æ”¹è¿›åå¤„ç†
        keep_grayscale: bool - æ˜¯å¦ä¿ç•™ç°åº¦ä¿¡æ¯ï¼ˆé¿å…é”¯é½¿ï¼‰
    
    Returns:
        numpy.ndarray - å¤„ç†åçš„mask (0-255)
    """
    # å¤„ç†å¼ é‡ç»´åº¦
    if model_mask.dim() == 4:
        model_mask = model_mask.squeeze(0)
    if model_mask.dim() == 3:
        model_mask = model_mask.mean(dim=0)  # å¤šé€šé“å–å¹³å‡
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    mask_np = model_mask.detach().cpu().numpy()
    
    # è°ƒæ•´å°ºå¯¸
    if mask_np.shape != target_size[::-1]:  # target_sizeæ˜¯(w,h)ï¼Œéœ€è¦è½¬æ¢ä¸º(h,w)
        mask_np = cv2.resize(mask_np, target_size, interpolation=cv2.INTER_LINEAR)
    
    # å½’ä¸€åŒ–åˆ°[0,255]
    mask_min, mask_max = mask_np.min(), mask_np.max()
    if mask_max > mask_min:
        mask_np = (mask_np - mask_min) / (mask_max - mask_min) * 255
    else:
        mask_np = np.zeros_like(mask_np) * 255
    
    mask_np = mask_np.astype(np.uint8)
    
    if keep_grayscale:
        # ä¿ç•™ç°åº¦ä¿¡æ¯ï¼Œé¿å…é”¯é½¿
        # æ£€æŸ¥åŸå§‹maskçš„å¹³å‡å€¼æ¥åˆ¤æ–­éœ€è¦å¦‚ä½•å¤„ç†æ–¹å‘
        mask_mean = np.mean(mask_np)
        
        # é‡æ–°åˆ¤æ–­maskæ–¹å‘ï¼šé€šå¸¸æ¨¡å‹è¾“å‡ºä¸­ï¼Œå°ç« åŒºåŸŸåº”è¯¥æ˜¯é«˜å€¼
        # å¦‚æœåŸå§‹maskå¹³å‡å€¼è¾ƒå¤§ï¼Œè¯´æ˜å¤§éƒ¨åˆ†æ˜¯é«˜å€¼ï¼ˆå¯èƒ½æ˜¯èƒŒæ™¯ï¼‰
        if mask_mean > 127.5:  # åŸå§‹maskåäº®ï¼Œå¯èƒ½éœ€è¦åè½¬
            processed_mask = 255 - mask_np  # åè½¬ï¼Œè®©å°ç« åŒºåŸŸå˜ä¸ºä½å€¼
        else:
            processed_mask = mask_np
        
        # ç°åº¦æ¨¡å¼çš„è´¨é‡æ”¹è¿›
        if enhance_quality:
            # 1. é«˜æ–¯æ¨¡ç³Šå¹³æ»‘è¾¹ç¼˜ï¼Œé¿å…é”¯é½¿
            processed_mask = cv2.GaussianBlur(processed_mask, (3, 3), 0.5)
            
            # 2. è½»å¾®çš„å¯¹æ¯”åº¦å¢å¼º
            processed_mask = cv2.convertScaleAbs(processed_mask, alpha=1.1, beta=0)
            
            # 3. ç¡®ä¿åœ¨[0,255]èŒƒå›´å†…
            processed_mask = np.clip(processed_mask, 0, 255)
    
    else:
        # ä¼ ç»ŸäºŒå€¼åŒ–æ¨¡å¼
        _, binary_mask = cv2.threshold(mask_np, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # æ£€æŸ¥åŸå§‹maskçš„å¹³å‡å€¼æ¥åˆ¤æ–­éœ€è¦å¦‚ä½•å¤„ç†
        mask_mean = np.mean(mask_np)
        
        # å¦‚æœåŸå§‹maskå¹³å‡å€¼è¾ƒå°ï¼Œè¯´æ˜å°ç« åŒºåŸŸæ˜¯ä½å€¼
        if mask_mean < 127.5:  # åŸå§‹maskåæš—ï¼Œå°ç« åŒºåŸŸæ˜¯ä½å€¼
            binary_mask = 255 - binary_mask  # åè½¬ï¼Œè®©å°ç« åŒºåŸŸå˜ä¸ºç™½è‰²
        
        # äºŒå€¼åŒ–æ¨¡å¼çš„è´¨é‡æ”¹è¿›
        if enhance_quality:
            # 1. å»é™¤å°å™ªå£°ç‚¹
            kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel_small)
            
            # 2. å¡«å……å°ç©ºæ´
            binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel_small)
            
            # 3. å¹³æ»‘è¾¹ç¼˜
            binary_mask = cv2.medianBlur(binary_mask, 3)
            
            # 4. è½»å¾®è†¨èƒ€ï¼Œç¡®ä¿å°ç« åŒºåŸŸå®Œæ•´
            kernel_dilate = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
            binary_mask = cv2.dilate(binary_mask, kernel_dilate, iterations=1)
        
        processed_mask = binary_mask
    
    return processed_mask.astype(np.uint8)


def extract_stamp_and_mask(original_image, cleaned_image, model_mask, enhance_mask=True, use_grayscale=True):
    """
    åŸºäºæ¨¡å‹maskçš„å°ç« æå–ç®—æ³• - æ”¯æŒç°åº¦å’ŒäºŒå€¼åŒ–
    
    Args:
        original_image: PIL Image - åŸå§‹å¸¦å°ç« å›¾åƒ
        cleaned_image: PIL Image - æ“¦é™¤å°ç« åçš„å›¾åƒ
        model_mask: torch.Tensor - æ¨¡å‹ç”Ÿæˆçš„å°ç« åŒºåŸŸmask
        enhance_mask: bool - æ˜¯å¦è¿›è¡Œmaskè´¨é‡æ”¹è¿›
        use_grayscale: bool - æ˜¯å¦ä½¿ç”¨ç°åº¦maskï¼ˆé¿å…é”¯é½¿ï¼‰
    
    Returns:
        stamp_image: PIL Image - æå–çš„å°ç« å›¾åƒ
        mask_image: PIL Image - å°ç« åŒºåŸŸmask
        stats: dict - æå–ç»Ÿè®¡ä¿¡æ¯
    """
    # ç¡®ä¿å›¾åƒå°ºå¯¸ä¸€è‡´
    if original_image.size != cleaned_image.size:
        cleaned_image = cleaned_image.resize(original_image.size, Image.BICUBIC)
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    orig_np = np.array(original_image)
    clean_np = np.array(cleaned_image)
    
    # å¤„ç†æ¨¡å‹mask
    processed_mask = process_model_mask(model_mask, original_image.size, 
                                       enhance_quality=enhance_mask, 
                                       keep_grayscale=use_grayscale)
    
    # æå–å°ç« 
    stamp_np = orig_np.copy()
    
    if use_grayscale:
        # ç°åº¦æ¨¡å¼ï¼šä½¿ç”¨è½¯æ··åˆï¼Œé¿å…é”¯é½¿
        mask_weight = processed_mask.astype(np.float32) / 255.0
        
        # ç°åœ¨processed_maskä¸­ï¼šä½å€¼=å°ç« åŒºåŸŸï¼Œé«˜å€¼=èƒŒæ™¯åŒºåŸŸ
        # ä½¿ç”¨é˜ˆå€¼æ¥å†³å®šå“ªäº›åŒºåŸŸè®¾ä¸ºç™½è‰²èƒŒæ™¯
        background_threshold = 0.5  # ä½¿ç”¨ä¸­å€¼ä½œä¸ºé˜ˆå€¼
        background_mask = mask_weight > background_threshold  # é«˜å€¼åŒºåŸŸä¸ºèƒŒæ™¯
        
        # å°†èƒŒæ™¯åŒºåŸŸè®¾ä¸ºç™½è‰²ï¼Œä¿ç•™å°ç« åŒºåŸŸ
        stamp_np[background_mask] = [255, 255, 255]
    else:
        # äºŒå€¼åŒ–æ¨¡å¼ï¼šç¡¬è¾¹ç¼˜
        # éœ€è¦é‡æ–°æ£€æŸ¥äºŒå€¼åŒ–åçš„maskæ–¹å‘
        stamp_np[processed_mask > 127] = [255, 255, 255]  # å°†é«˜å€¼åŒºåŸŸè®¾ä¸ºç™½è‰²èƒŒæ™¯
    
    # è½¬æ¢ä¸ºPILå›¾åƒ
    stamp_image = Image.fromarray(stamp_np)
    mask_image = Image.fromarray(processed_mask, mode='L')
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    total_pixels = processed_mask.shape[0] * processed_mask.shape[1]
    
    if use_grayscale:
        # ç°åº¦æ¨¡å¼ï¼šç»Ÿè®¡ä½å€¼åŒºåŸŸä½œä¸ºå°ç« 
        stamp_pixels = np.sum(processed_mask <= 127)  # ä½äºç­‰äºä¸­å€¼çš„åƒç´ ä¸ºå°ç« 
    else:
        # äºŒå€¼åŒ–æ¨¡å¼ï¼šç»Ÿè®¡ä½å€¼åŒºåŸŸä½œä¸ºå°ç« 
        stamp_pixels = np.sum(processed_mask <= 127)
    
    stamp_ratio = stamp_pixels / total_pixels if total_pixels > 0 else 0
    
    # è®¡ç®—åŸå›¾å’Œæ¸…ç†å›¾çš„LABå·®å¼‚ï¼ˆç”¨äºè´¨é‡è¯„ä¼°ï¼‰
    try:
        orig_lab = color.rgb2lab(orig_np / 255.0)
        clean_lab = color.rgb2lab(clean_np / 255.0)
        lab_diff = np.sqrt(np.sum((orig_lab - clean_lab) ** 2, axis=2))
        max_lab_diff = np.max(lab_diff)
        mean_lab_diff = np.mean(lab_diff)
        
        # è®¡ç®—å°ç« åŒºåŸŸçš„å¹³å‡LABå·®å¼‚
        stamp_lab_diff = np.mean(lab_diff[processed_mask <= 127]) if stamp_pixels > 0 else 0
    except Exception:
        max_lab_diff = mean_lab_diff = stamp_lab_diff = 0
    
    stats = {
        'total_pixels': total_pixels,
        'stamp_pixels': stamp_pixels,
        'stamp_ratio': stamp_ratio,
        'max_lab_diff': max_lab_diff,
        'mean_lab_diff': mean_lab_diff,
        'stamp_lab_diff': stamp_lab_diff,
        'method': 'model_mask_grayscale' if use_grayscale else 'model_mask_binary'
    }
    
    return stamp_image, mask_image, stats


def ensure_dir(file_path):
    """ç¡®ä¿æ–‡ä»¶è·¯å¾„çš„ç›®å½•å­˜åœ¨"""
    directory = os.path.dirname(file_path)
    if directory and not os.path.exists(directory):
        os.makedirs(directory, exist_ok=True)


def tensor_to_pil(tensor):
    """å°†tensorè½¬æ¢ä¸ºPILå›¾åƒ"""
    if tensor.dim() == 4:
        tensor = tensor.squeeze(0)
    
    # ç¡®ä¿åœ¨[0,1]èŒƒå›´å†…
    tensor = torch.clamp(tensor, 0, 1)
    
    # è½¬æ¢ä¸ºnumpyå¹¶è°ƒæ•´ç»´åº¦é¡ºåº
    np_array = tensor.permute(1, 2, 0).numpy()
    np_array = (np_array * 255).astype(np.uint8)
    
    return Image.fromarray(np_array)


def compute_image_quality_metrics(image_tensor, original_tensor):
    """
    è®¡ç®—å›¾åƒè´¨é‡æŒ‡æ ‡
    
    Args:
        image_tensor: å¤„ç†åçš„å›¾åƒå¼ é‡
        original_tensor: åŸå§‹å›¾åƒå¼ é‡
    
    Returns:
        dict: è´¨é‡æŒ‡æ ‡å­—å…¸
    """
    # è½¬æ¢ä¸ºnumpyè¿›è¡Œè®¡ç®—
    if image_tensor.dim() == 4:
        image_tensor = image_tensor.squeeze(0)
    if original_tensor.dim() == 4:
        original_tensor = original_tensor.squeeze(0)
    
    # ç¡®ä¿ä¸¤ä¸ªå¼ é‡å°ºå¯¸ä¸€è‡´
    if image_tensor.shape != original_tensor.shape:
        # å°†image_tensorè°ƒæ•´åˆ°original_tensorçš„å°ºå¯¸
        target_size = original_tensor.shape[1:]  # (H, W)
        image_tensor = torch.nn.functional.interpolate(
            image_tensor.unsqueeze(0), size=target_size, mode='bilinear', align_corners=False
        ).squeeze(0)
    
    img_np = image_tensor.permute(1, 2, 0).detach().cpu().numpy()
    orig_np = original_tensor.permute(1, 2, 0).detach().cpu().numpy()
    
    # ç¡®ä¿åœ¨[0,1]èŒƒå›´å†…
    img_np = np.clip(img_np, 0, 1)
    orig_np = np.clip(orig_np, 0, 1)
    
    # 1. MSE (è¶Šå°è¶Šå¥½)
    mse = np.mean((img_np - orig_np) ** 2)
    
    # 2. PSNR (è¶Šå¤§è¶Šå¥½)
    if mse > 0:
        psnr = 20 * np.log10(1.0 / np.sqrt(mse))
    else:
        psnr = float('inf')
    
    # 3. ç»“æ„ç›¸ä¼¼æ€§ (ç®€åŒ–ç‰ˆSSIM)
    def simple_ssim(x, y):
        mu_x = np.mean(x)
        mu_y = np.mean(y)
        sigma_x = np.var(x)
        sigma_y = np.var(y)
        sigma_xy = np.mean((x - mu_x) * (y - mu_y))
        
        c1 = 0.01 ** 2
        c2 = 0.03 ** 2
        
        ssim = ((2 * mu_x * mu_y + c1) * (2 * sigma_xy + c2)) / \
               ((mu_x ** 2 + mu_y ** 2 + c1) * (sigma_x + sigma_y + c2))
        return ssim
    
    ssim = simple_ssim(img_np, orig_np)
    
    # 4. è¾¹ç¼˜ä¿æŒåº¦ (è®¡ç®—æ¢¯åº¦ç›¸ä¼¼æ€§)
    def compute_gradient_magnitude(img):
        gray = np.mean(img, axis=2) if len(img.shape) == 3 else img
        grad_x = np.gradient(gray, axis=1)
        grad_y = np.gradient(gray, axis=0)
        return np.sqrt(grad_x**2 + grad_y**2)
    
    grad_orig = compute_gradient_magnitude(orig_np)
    grad_img = compute_gradient_magnitude(img_np)
    edge_preservation = np.corrcoef(grad_orig.flatten(), grad_img.flatten())[0, 1]
    if np.isnan(edge_preservation):
        edge_preservation = 0
    
    # 5. é¢œè‰²ä¸€è‡´æ€§ (LABç©ºé—´å·®å¼‚)
    try:
        orig_lab = color.rgb2lab(orig_np)
        img_lab = color.rgb2lab(img_np)
        color_diff = np.mean(np.sqrt(np.sum((orig_lab - img_lab) ** 2, axis=2)))
    except:
        color_diff = 0
    
    return {
        'mse': mse,
        'psnr': psnr,
        'ssim': ssim,
        'edge_preservation': edge_preservation,
        'color_diff': color_diff,
        'quality_score': psnr * 0.4 + ssim * 30 + edge_preservation * 20 - color_diff * 2
    }


def select_best_output_combination(outputs, original_tensor, masks, verbose=False):
    """
    ä»å¤šä¸ªæ¨¡å‹è¾“å‡ºä¸­é€‰æ‹©æœ€ä½³ç»„åˆ
    
    Args:
        outputs: dict - åŒ…å«æ‰€æœ‰æ¨¡å‹è¾“å‡ºçš„å­—å…¸
        original_tensor: åŸå§‹å›¾åƒå¼ é‡
        masks: dict - åŒ…å«ä¸åŒmaskçš„å­—å…¸
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        tuple: (æœ€ä½³æ¸…ç†å›¾åƒ, æœ€ä½³mask, è´¨é‡ç»Ÿè®¡)
    """
    # è·å–ç›®æ ‡å°ºå¯¸ï¼ˆä½¿ç”¨åŸå§‹è¾“å…¥çš„å°ºå¯¸ï¼‰
    if original_tensor.dim() == 4:
        target_size = original_tensor.shape[2:]  # (H, W)
    else:
        target_size = original_tensor.shape[1:]  # (H, W)
    
    # å°†æ‰€æœ‰è¾“å‡ºè°ƒæ•´åˆ°ç›¸åŒå°ºå¯¸
    candidates = {}
    for name, output in outputs.items():
        if output.dim() == 4:
            output = output.squeeze(0)
        
        # è°ƒæ•´å°ºå¯¸
        if output.shape[1:] != target_size:
            output = torch.nn.functional.interpolate(
                output.unsqueeze(0), size=target_size, mode='bilinear', align_corners=False
            ).squeeze(0)
        
        candidates[{
            'out1': 'scale1_output',
            'out2': 'scale2_output', 
            'out3': 'unet_output',
            'g_images': 'final_refined'
        }.get(name, name)] = output
    
    # è®¡ç®—æ¯ä¸ªå€™é€‰è¾“å‡ºçš„è´¨é‡æŒ‡æ ‡
    quality_results = {}
    for name, output in candidates.items():
        try:
            metrics = compute_image_quality_metrics(output, original_tensor)
            quality_results[name] = metrics
            
            if verbose:
                print(f"ğŸ“Š {name}: PSNR={metrics['psnr']:.2f}, SSIM={metrics['ssim']:.3f}, "
                      f"Edge={metrics['edge_preservation']:.3f}, Quality={metrics['quality_score']:.2f}")
        except Exception as e:
            if verbose:
                print(f"âš ï¸ {name}: è´¨é‡è¯„ä¼°å¤±è´¥ - {str(e)}")
            # ä¸ºå¤±è´¥çš„è¾“å‡ºåˆ†é…ä½è´¨é‡åˆ†æ•°
            quality_results[name] = {
                'mse': float('inf'),
                'psnr': 0,
                'ssim': 0,
                'edge_preservation': 0,
                'color_diff': float('inf'),
                'quality_score': -1000
            }
    
    # é€‰æ‹©è´¨é‡åˆ†æ•°æœ€é«˜çš„è¾“å‡º
    best_name = max(quality_results.keys(), key=lambda x: quality_results[x]['quality_score'])
    best_output = candidates[best_name]
    
    # ä¸ºæœ€ä½³è¾“å‡ºé€‰æ‹©æœ€åˆé€‚çš„mask
    best_mask = masks['mm']  # é»˜è®¤ä½¿ç”¨æ¨¡å‹ç”Ÿæˆçš„mask
    
    # å¦‚æœæœ€ä½³è¾“å‡ºä¸æ˜¯æœ€ç»ˆç²¾ç‚¼ç‰ˆæœ¬ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´maskç­–ç•¥
    if best_name != 'final_refined':
        if verbose:
            print(f"ğŸ¯ é€‰æ‹©äº†éæœ€ç»ˆè¾“å‡º {best_name}ï¼Œä¿æŒåŸå§‹maskç­–ç•¥")
    
    return best_output, best_mask, {
        'best_output': best_name,
        'all_metrics': quality_results,
        'best_metrics': quality_results[best_name]
    }


def create_ensemble_output(outputs, weights=None, verbose=False):
    """
    åˆ›å»ºå¤šè¾“å‡ºçš„é›†æˆç»“æœ
    
    Args:
        outputs: dict - åŒ…å«æ‰€æœ‰æ¨¡å‹è¾“å‡ºçš„å­—å…¸
        weights: dict - æ¯ä¸ªè¾“å‡ºçš„æƒé‡
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        torch.Tensor: é›†æˆåçš„è¾“å‡º
    """
    if weights is None:
        # é»˜è®¤æƒé‡ï¼šæœ€ç»ˆç²¾ç‚¼è¾“å‡ºæƒé‡æœ€é«˜
        weights = {
            'g_images': 0.5,    # æœ€ç»ˆç²¾ç‚¼è¾“å‡º
            'out3': 0.25,       # UNetè¾“å‡º
            'out2': 0.15,       # å°ºåº¦2è¾“å‡º
            'out1': 0.1         # å°ºåº¦1è¾“å‡º
        }
    
    # ä½¿ç”¨æœ€ç»ˆç²¾ç‚¼è¾“å‡ºä½œä¸ºç›®æ ‡å°ºå¯¸
    reference_output = outputs['g_images']
    if reference_output.dim() == 4:
        reference_output = reference_output.squeeze(0)
    target_size = reference_output.shape
    ensemble_result = torch.zeros_like(reference_output)
    
    total_weight = 0
    for output_name, weight in weights.items():
        if output_name in outputs:
            output = outputs[output_name]
            
            # ç¡®ä¿ç»´åº¦ä¸€è‡´
            if output.dim() == 4:
                output = output.squeeze(0)
            
            # è°ƒæ•´å°ºå¯¸åˆ°ç›®æ ‡å¤§å°
            if output.shape != target_size:
                output = torch.nn.functional.interpolate(
                    output.unsqueeze(0), size=target_size[1:], mode='bilinear', align_corners=False
                ).squeeze(0)
            
            ensemble_result += output * weight
            total_weight += weight
            
            if verbose:
                print(f"ğŸ“Š é›†æˆ {output_name}: æƒé‡={weight:.2f}, å°ºå¯¸={output.shape}")
    
    # å½’ä¸€åŒ–
    if total_weight > 0:
        ensemble_result /= total_weight
    
    return ensemble_result


def process_image(model_path, input_image_path, output_path, verbose=True, save_debug=False, extract_stamp=True, enhance_mask=True, use_grayscale_mask=True, use_ensemble=False, use_best_selection=True):
    """
    å¤„ç†å•å¼ å›¾åƒ - å°ç« æ“¦é™¤ + å¤šè¾“å‡ºèåˆ + åŸºäºç°åº¦/äºŒå€¼åŒ–çš„å°ç« æå–
    
    Args:
        save_debug: å¦‚æœä¸ºTrueï¼Œä¿å­˜è°ƒè¯•è¾“å‡ºï¼ˆå¤šå°ºåº¦è¾“å‡ºå’ŒåŸå§‹æ¨¡å‹maskï¼‰
        extract_stamp: å¦‚æœä¸ºTrueï¼Œæå–å°ç« å’Œç”Ÿæˆmask
        enhance_mask: å¦‚æœä¸ºTrueï¼Œè¿›è¡Œmaskè´¨é‡æ”¹è¿›
        use_grayscale_mask: å¦‚æœä¸ºTrueï¼Œä½¿ç”¨ç°åº¦maskï¼ˆé¿å…é”¯é½¿ï¼‰
        use_ensemble: å¦‚æœä¸ºTrueï¼Œä½¿ç”¨é›†æˆè¾“å‡º
        use_best_selection: å¦‚æœä¸ºTrueï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä½³è¾“å‡º
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    if verbose:
        print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    if verbose:
        print("ğŸ”§ åŠ è½½æ¨¡å‹...")
    model = STRnet2(3)
    
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location=device))
        if verbose:
            print(f"âœ… åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {os.path.basename(model_path)}")
    else:
        if verbose:
            print("âš ï¸  ä½¿ç”¨éšæœºåˆå§‹åŒ–æ¨¡å‹ï¼ˆæ¼”ç¤ºæ¨¡å¼ï¼‰")
    
    model.to(device)
    model.eval()
    
    # å¤„ç†å›¾åƒ
    if verbose:
        print(f"ğŸ–¼ï¸  å¤„ç†å›¾åƒ: {os.path.basename(input_image_path)}")
    
    input_tensor = load_image(input_image_path).to(device)
    
    # åŠ è½½åŸå§‹å›¾åƒç”¨äºå¯¹æ¯”
    original_pil = Image.open(input_image_path).convert('RGB')
    
    with torch.no_grad():
        # è·å–æ¨¡å‹çš„æ‰€æœ‰è¾“å‡º
        out1, out2, out3, g_images, mm = model(input_tensor)
        
        # è½¬æ¢åˆ°CPUå¹¶ç»„ç»‡æ‰€æœ‰è¾“å‡º
        outputs = {
            'out1': out1.data.cpu(),
            'out2': out2.data.cpu(),
            'out3': out3.data.cpu(),
            'g_images': g_images.data.cpu(),
        }
        
        masks = {
            'mm': mm.data.cpu()
        }
        
        # é€‰æ‹©æœ€ä½³è¾“å‡ºç­–ç•¥
        if use_ensemble:
            # ä½¿ç”¨é›†æˆè¾“å‡º
            if verbose:
                print("ğŸ”„ ä½¿ç”¨å¤šè¾“å‡ºé›†æˆç­–ç•¥")
            result = create_ensemble_output(outputs, verbose=verbose)
            final_mask = masks['mm']
            selection_stats = {'method': 'ensemble'}
            
        elif use_best_selection:
            # è‡ªåŠ¨é€‰æ‹©æœ€ä½³è¾“å‡º
            if verbose:
                print("ğŸ¯ è‡ªåŠ¨é€‰æ‹©æœ€ä½³è¾“å‡º")
            result, final_mask, selection_stats = select_best_output_combination(
                outputs, input_tensor.cpu(), masks, verbose=verbose
            )
            
        else:
            # ä½¿ç”¨ä¼ ç»Ÿçš„æœ€ç»ˆç²¾ç‚¼è¾“å‡º
            if verbose:
                print("ğŸ“± ä½¿ç”¨ä¼ ç»Ÿæœ€ç»ˆç²¾ç‚¼è¾“å‡º")
            result = outputs['g_images']
            final_mask = masks['mm']
            selection_stats = {'method': 'traditional', 'best_output': 'final_refined'}
        
        # è½¬æ¢ä¸ºPILå›¾åƒç”¨äºå°ç« æå–
        # ç¡®ä¿resultæ˜¯æ­£ç¡®çš„ç»´åº¦
        if result.dim() == 4:
            result = result.squeeze(0)
        cleaned_pil = tensor_to_pil(result)
        
        # è°ƒè¯•æ¨¡å¼ï¼šä¿å­˜æ‰€æœ‰è¾“å‡ºå’Œè´¨é‡å¯¹æ¯”
        if save_debug:
            # ä¿å­˜æ‰€æœ‰æ¨¡å‹è¾“å‡º
            for output_name, output_tensor in outputs.items():
                debug_path = output_path.replace('.jpg', f'_debug_{output_name}.jpg')
                ensure_dir(debug_path)
                save_result(output_tensor, debug_path)
            
            # ä¿å­˜è´¨é‡å¯¹æ¯”æŠ¥å‘Š
            if use_best_selection and 'all_metrics' in selection_stats:
                quality_report_path = output_path.replace('.jpg', '_quality_report.txt')
                ensure_dir(quality_report_path)
                
                with open(quality_report_path, 'w', encoding='utf-8') as f:
                    f.write("=== å¤šè¾“å‡ºè´¨é‡å¯¹æ¯”æŠ¥å‘Š ===\n\n")
                    f.write(f"é€‰æ‹©çš„æœ€ä½³è¾“å‡º: {selection_stats['best_output']}\n\n")
                    
                    for name, metrics in selection_stats['all_metrics'].items():
                        f.write(f"{name}:\n")
                        f.write(f"  PSNR: {metrics['psnr']:.2f}\n")
                        f.write(f"  SSIM: {metrics['ssim']:.3f}\n")
                        f.write(f"  è¾¹ç¼˜ä¿æŒ: {metrics['edge_preservation']:.3f}\n")
                        f.write(f"  é¢œè‰²å·®å¼‚: {metrics['color_diff']:.2f}\n")
                        f.write(f"  ç»¼åˆè´¨é‡åˆ†: {metrics['quality_score']:.2f}\n\n")
            
            if verbose:
                print(f"ğŸ”§ è°ƒè¯•è¾“å‡ºå·²ä¿å­˜ (åŒ…å«æ‰€æœ‰æ¨¡å‹è¾“å‡º)")
                if 'best_output' in selection_stats:
                    print(f"ğŸ¯ æœ€ä½³è¾“å‡º: {selection_stats['best_output']}")
        
        # æå–å°ç« å’Œç”Ÿæˆmask
        if extract_stamp:
            if verbose:
                mode_str = "ç°åº¦mask" if use_grayscale_mask else "äºŒå€¼åŒ–mask"
                print(f"ğŸ” æå–å°ç«  ({mode_str})")
            
            # ä½¿ç”¨æ”¹è¿›çš„å°ç« æå–ç®—æ³•ï¼ˆä½¿ç”¨é€‰æ‹©çš„æœ€ä½³maskï¼‰
            # ç¡®ä¿final_maskç»´åº¦æ­£ç¡®
            if final_mask.dim() == 4:
                final_mask = final_mask.squeeze(0)
            
            stamp_image, mask_image, diff_stats = extract_stamp_and_mask(
                original_pil, cleaned_pil, final_mask, 
                enhance_mask=enhance_mask,
                use_grayscale=use_grayscale_mask
            )
            
            # æ·»åŠ é€‰æ‹©ç­–ç•¥ä¿¡æ¯åˆ°ç»Ÿè®¡ä¸­
            diff_stats.update({
                'selection_method': selection_stats.get('method', 'unknown'),
                'selected_output': selection_stats.get('best_output', 'unknown')
            })
            
            # ä¿å­˜å¿…è¦è¾“å‡ºï¼šå°ç« å’Œmask
            stamp_path = output_path.replace('.jpg', '_stamp.jpg')
            mask_path = output_path.replace('.jpg', '_mask.png')
            
            ensure_dir(stamp_path)
            ensure_dir(mask_path)
            
            stamp_image.save(stamp_path)
            mask_image.save(mask_path)
            
            # è°ƒè¯•æ¨¡å¼ï¼šä¿å­˜åŸå§‹æ¨¡å‹maskå’Œæœ€ç»ˆä½¿ç”¨çš„mask
            if save_debug:
                # ä¿å­˜åŸå§‹æ¨¡å‹mask
                model_mask_path = output_path.replace('.jpg', '_debug_model_mask.png')
                ensure_dir(model_mask_path)
                model_mask_vis = tensor_to_pil(masks['mm'])
                model_mask_vis.save(model_mask_path)
                
                # æ€»æ˜¯ä¿å­˜æœ€ç»ˆä½¿ç”¨çš„maskï¼ˆå³ä½¿ç›¸åŒä¹Ÿä¿å­˜ï¼Œä¾¿äºè°ƒè¯•å¯¹æ¯”ï¼‰
                final_mask_path = output_path.replace('.jpg', '_debug_final_mask.png')
                ensure_dir(final_mask_path)
                final_mask_vis = tensor_to_pil(final_mask)
                final_mask_vis.save(final_mask_path)
                
                if verbose:
                    if torch.equal(final_mask, masks['mm']):
                        print(f"ğŸ”§ æœ€ç»ˆmaskä¸æ¨¡å‹maskç›¸åŒ")
                    else:
                        print(f"ğŸ”§ æœ€ç»ˆmaskä¸æ¨¡å‹maskä¸åŒ")
            
            if verbose:
                print(f"ğŸ“„ å°ç« ä¿å­˜åˆ°: {os.path.basename(stamp_path)}")
                print(f"ğŸ­ Maskä¿å­˜åˆ°: {os.path.basename(mask_path)}")
                print(f"ğŸ“Š å°ç« åŒºåŸŸå æ¯”: {diff_stats['stamp_ratio']:.2%}")
                print(f"ğŸ“Š å°ç« åŒºåŸŸLABå·®å¼‚: {diff_stats['stamp_lab_diff']:.2f}")
                print(f"ğŸ“Š æ•´ä½“LABå·®å¼‚: {diff_stats['mean_lab_diff']:.2f}")
                print(f"ğŸ¯ ä½¿ç”¨è¾“å‡º: {diff_stats.get('selected_output', 'unknown')}")
                print(f"ğŸ”„ é€‰æ‹©æ–¹æ³•: {diff_stats.get('selection_method', 'unknown')}")
                if save_debug:
                    print(f"ğŸ”§ è°ƒè¯•æ–‡ä»¶å·²ä¿å­˜ (åŒ…å«è´¨é‡å¯¹æ¯”æŠ¥å‘Š)")
    
    # ä¿å­˜æœ€ç»ˆç»“æœ
    ensure_dir(output_path)
    save_result(result, output_path)
    
    if verbose:
        print(f"âœ… å®Œæˆ! ä¿å­˜åˆ°: {output_path}")
        if save_debug:
            print("ğŸ”§ è°ƒè¯•æ¨¡å¼: å·²ä¿å­˜é¢å¤–çš„è°ƒè¯•æ–‡ä»¶")
    
    return output_path


def batch_process(model_path, input_dir, output_dir, extract_stamp=True, use_ensemble=False, use_best_selection=True, save_debug_masks=False):
    """æ‰¹é‡å¤„ç†å›¾åƒï¼ŒåŒ…å«åŸºäºå¤šè¾“å‡ºèåˆçš„å°ç« æå–"""
    supported_formats = ('.png', '.jpg', '.jpeg', '.bmp', '.PNG', '.JPG', '.JPEG', '.BMP')
    
    # è·å–å›¾åƒæ–‡ä»¶
    image_files = []
    for root, dirs, files in os.walk(input_dir):
        for file in files:
            if file.endswith(supported_formats):
                image_files.append(os.path.join(root, file))
    
    if not image_files:
        print(f"âŒ åœ¨ç›®å½• {input_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
    os.makedirs(output_dir, exist_ok=True)
    
    # æ‰¹é‡å¤„ç†
    success_count = 0
    for i, image_path in enumerate(image_files):
        print(f"ğŸ“Š è¿›åº¦: {i+1}/{len(image_files)} - {os.path.basename(image_path)}")
        try:
            output_filename = f"cleaned_{os.path.basename(image_path).replace('.png', '.jpg')}"
            output_path = os.path.join(output_dir, output_filename)
            process_image(
                model_path=model_path, 
                input_image_path=image_path, 
                output_path=output_path, 
                verbose=False,
                save_debug=save_debug_masks,
                extract_stamp=extract_stamp,
                use_ensemble=use_ensemble,
                use_best_selection=use_best_selection
            )
            success_count += 1
        except Exception as e:
            print(f"âŒ å¤„ç† {os.path.basename(image_path)} å‡ºé”™: {str(e)}")
    
    print(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ! æˆåŠŸå¤„ç† {success_count}/{len(image_files)} ä¸ªæ–‡ä»¶")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
    if extract_stamp:
        print("ğŸ“„ æ¯ä¸ªæ–‡ä»¶ç”Ÿæˆ: æ¸…ç†å›¾åƒ + å°ç« å›¾åƒ + Maskå›¾åƒ")


def quick_demo():
    """å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼ - å¤šè¾“å‡ºèåˆç‰ˆæœ¬"""
    print("ğŸš€ å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼ (å¤šè¾“å‡ºèåˆ)")
    print("-" * 50)
    
    # åˆ›å»ºæ¼”ç¤ºå›¾åƒ
    demo_image = create_demo_image()
    demo_path = "demo_input.jpg"
    demo_image.save(demo_path)
    print(f"ğŸ“ åˆ›å»ºæ¼”ç¤ºå›¾åƒ: {demo_path}")
    
    # å¤„ç†å›¾åƒ - å¤šè¾“å‡ºèåˆæ¨¡å¼
    output_path = "demo_output_final.jpg"
    process_image("./models/pre_model.pth", demo_path, output_path, save_debug=True, use_best_selection=True)
    
    print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆ!")
    print(f"   è¾“å…¥å›¾åƒ: {demo_path}")
    print(f"   æ¸…ç†å›¾åƒ: {output_path}")
    print(f"   å°ç« å›¾åƒ: demo_output_final_stamp.jpg")
    print(f"   Maskå›¾åƒ: demo_output_final_mask.png")
    print("\nğŸ”§ ç®—æ³•è¯´æ˜:")
    print("   - å……åˆ†åˆ©ç”¨æ¨¡å‹çš„5ä¸ªè¾“å‡ºï¼šout1, out2, out3, g_images, mm")
    print("   - è‡ªåŠ¨è´¨é‡è¯„ä¼°ï¼šPSNR, SSIM, è¾¹ç¼˜ä¿æŒåº¦, é¢œè‰²ä¸€è‡´æ€§")
    print("   - æ™ºèƒ½è¾“å‡ºé€‰æ‹©ï¼šè‡ªåŠ¨é€‰æ‹©è´¨é‡æœ€ä½³çš„æ¨¡å‹è¾“å‡º")
    print("   - å¤šè¾“å‡ºèåˆï¼šå¯é€‰çš„åŠ æƒé›†æˆç­–ç•¥")
    print("   - å¢å¼ºå°ç« æå–ï¼šåŸºäºæœ€ä½³è¾“å‡ºçš„å°ç« åˆ†ç¦»")
    
    return demo_path, output_path


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å°ç« æ“¦é™¤ç³»ç»Ÿ (å¤šè¾“å‡ºèåˆå°ç« æå–)')
    parser.add_argument('--model_path', type=str, default='./models/pre_model.pth',
                        help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--input_image', type=str, default=r'image\2.png', help='è¾“å…¥å›¾åƒè·¯å¾„')
    parser.add_argument('--input_dir', type=str, help='è¾“å…¥å›¾åƒç›®å½•ï¼ˆæ‰¹é‡å¤„ç†ï¼‰')
    parser.add_argument('--output_path', type=str, default='./results/cleaned_image.jpg',
                        help='è¾“å‡ºå›¾åƒè·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./results/',
                        help='è¾“å‡ºç›®å½•ï¼ˆæ‰¹é‡å¤„ç†ï¼‰')
    parser.add_argument('--debug', action='store_true',
                        help='è°ƒè¯•æ¨¡å¼ï¼šä¿å­˜é¢å¤–çš„è°ƒè¯•æ–‡ä»¶')
    parser.add_argument('--no_extract', action='store_true',
                        help='ä¸æå–å°ç« å’Œmask')
    parser.add_argument('--no_enhance_mask', action='store_true',
                        help='ä¸è¿›è¡Œmaskè´¨é‡æ”¹è¿›åå¤„ç†')
    parser.add_argument('--binary_mask', action='store_true',
                        help='ä½¿ç”¨äºŒå€¼åŒ–maskï¼ˆé»˜è®¤ä½¿ç”¨ç°åº¦maské¿å…é”¯é½¿ï¼‰')
    parser.add_argument('--ensemble', action='store_true',
                        help='ä½¿ç”¨å¤šè¾“å‡ºé›†æˆç­–ç•¥ï¼ˆåŠ æƒèåˆæ‰€æœ‰è¾“å‡ºï¼‰')
    parser.add_argument('--no_auto_select', action='store_true',
                        help='ç¦ç”¨è‡ªåŠ¨æœ€ä½³è¾“å‡ºé€‰æ‹©ï¼ˆä½¿ç”¨ä¼ ç»Ÿæœ€ç»ˆè¾“å‡ºï¼‰')
    parser.add_argument('--batch_debug_masks', action='store_true',
                        help='æ‰¹é‡å¤„ç†æ—¶ä¿å­˜è°ƒè¯•maskæ–‡ä»¶')
    
    args = parser.parse_args()
    
    print("=" * 50)
    print("ğŸ¯ å°ç« æ“¦é™¤ç³»ç»Ÿ")
    print("=" * 50)
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        return
    
    print()
    
    try:
        if args.input_image:
            # å•å¼ å›¾åƒå¤„ç†
            if not os.path.exists(args.input_image):
                print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {args.input_image}")
                return
            mode_desc = "äºŒå€¼åŒ–" if args.binary_mask else "ç°åº¦"
            strategy_desc = "é›†æˆ" if args.ensemble else ("æ™ºèƒ½é€‰æ‹©" if not args.no_auto_select else "ä¼ ç»Ÿ")
            print(f"ğŸ“· å•å¼ å›¾åƒå¤„ç†æ¨¡å¼ ({mode_desc}mask, {strategy_desc}ç­–ç•¥)")
            process_image(
                model_path=args.model_path, 
                input_image_path=args.input_image, 
                output_path=args.output_path, 
                save_debug=args.debug,
                extract_stamp=not args.no_extract,
                enhance_mask=not args.no_enhance_mask,
                use_grayscale_mask=not args.binary_mask,
                use_ensemble=args.ensemble,
                use_best_selection=not args.no_auto_select
            )
            
        elif args.input_dir:
            # æ‰¹é‡å¤„ç†
            if not os.path.exists(args.input_dir):
                print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {args.input_dir}")
                return
            strategy_desc = "é›†æˆ" if args.ensemble else ("æ™ºèƒ½é€‰æ‹©" if not args.no_auto_select else "ä¼ ç»Ÿ")
            print(f"ğŸ“ æ‰¹é‡å¤„ç†æ¨¡å¼ ({strategy_desc}ç­–ç•¥å°ç« æå–)")
            batch_process(args.model_path, args.input_dir, args.output_dir, 
                         extract_stamp=not args.no_extract,
                         use_ensemble=args.ensemble,
                         use_best_selection=not args.no_auto_select,
                         save_debug_masks=args.batch_debug_masks)
            
        else:
            # é»˜è®¤æ¼”ç¤ºæ¨¡å¼
            quick_demo()
            print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
            print("  å•å¼ å¤„ç†: python example.py --input_image image.jpg")
            print("  æ‰¹é‡å¤„ç†: python example.py --input_dir images/ --output_dir results/")
            print("  æ‰¹é‡è°ƒè¯•mask: python example.py --input_dir images/ --batch_debug_masks")
            print("  é›†æˆç­–ç•¥: python example.py --input_image image.jpg --ensemble")
            print("  ä¼ ç»Ÿæ¨¡å¼: python example.py --input_image image.jpg --no_auto_select")
            print("  è°ƒè¯•æ¨¡å¼: python example.py --input_image image.jpg --debug")
            print("  äºŒå€¼åŒ–mask: python example.py --input_image image.jpg --binary_mask")
            
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {str(e)}")
        print("è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å’Œä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…")


if __name__ == "__main__":
    main()
